{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1898721,"sourceType":"datasetVersion","datasetId":1131493},{"sourceId":5552662,"sourceType":"datasetVersion","datasetId":3198793},{"sourceId":14663127,"sourceType":"datasetVersion","datasetId":9367436},{"sourceId":735204,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":560442,"modelId":573029}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#installing dependencies\n!pip install -q transformers datasets peft bitsandbytes accelerate\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T05:32:39.164463Z","iopub.execute_input":"2026-01-30T05:32:39.164740Z","iopub.status.idle":"2026-01-30T05:32:47.968581Z","shell.execute_reply.started":"2026-01-30T05:32:39.164708Z","shell.execute_reply":"2026-01-30T05:32:47.967728Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#imports\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\nfrom peft import LoraConfig, get_peft_model\nfrom datasets import Dataset\nfrom peft import PeftModel\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T05:32:47.973256Z","iopub.execute_input":"2026-01-30T05:32:47.973541Z","iopub.status.idle":"2026-01-30T05:33:35.868450Z","shell.execute_reply.started":"2026-01-30T05:32:47.973504Z","shell.execute_reply":"2026-01-30T05:33:35.867821Z"}},"outputs":[{"name":"stderr","text":"2026-01-30 05:33:11.522121: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769751191.961476      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769751192.099316      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769751193.200763      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769751193.200807      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769751193.200810      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769751193.200812      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#Loading the model \nmodel_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    load_in_4bit=True,\n    device_map=\"auto\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T05:36:52.775232Z","iopub.execute_input":"2026-01-30T05:36:52.776073Z","iopub.status.idle":"2026-01-30T05:37:13.075652Z","shell.execute_reply.started":"2026-01-30T05:36:52.776037Z","shell.execute_reply":"2026-01-30T05:37:13.074872Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c9f9bb7935945ef956be9fb9424f579"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b95503d2d9314cfca3b14a3dcbf921ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d2f98e3576e4574ba91eb172ed7632e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3955976daa54e76afc14f364e556004"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57acef8006cf4b49825cc1b5f0a8895a"}},"metadata":{}},{"name":"stderr","text":"The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40f2cdeee3d249758437318b5b293667"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7518961fbd09462bbf308edc8dcf8bcf"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"#lora-config for fine-tuning\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T05:37:30.942864Z","iopub.execute_input":"2026-01-30T05:37:30.944216Z","iopub.status.idle":"2026-01-30T05:37:31.438220Z","shell.execute_reply.started":"2026-01-30T05:37:30.944176Z","shell.execute_reply":"2026-01-30T05:37:31.437260Z"}},"outputs":[{"name":"stdout","text":"trainable params: 1,126,400 || all params: 1,101,174,784 || trainable%: 0.1023\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"#importing the datasets for finetuning\nimport pandas as pd\ndf = pd.read_csv(\"/kaggle/input/imdb-movies-dataset/imdb_movies.csv\")\ndf.head()\n\n\ndata = []\n\nfor _, row in df.iterrows():\n    title = row[\"names\"]\n    overview = row[\"overview\"]\n    genre = row[\"genre\"]\n    score = row[\"score\"]\n\n    # Q1: plot explanation\n    q1 = f\"What is the movie {title} about?\"\n    a1 = overview\n\n    data.append({\n        \"text\": f\"### Question: {q1}\\n### Answer: {a1}\"\n    })\n\n    # Q2: genre-based recommendation\n    q2 = f\"Recommend a {genre} movie.\"\n    a2 = f\"{title} is a good recommendation. It has a user score of {score}. {overview}\"\n\n    data.append({\n        \"text\": f\"### Question: {q2}\\n### Answer: {a2}\"\n    })\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T05:40:14.403470Z","iopub.execute_input":"2026-01-30T05:40:14.404312Z","iopub.status.idle":"2026-01-30T05:40:14.561532Z","shell.execute_reply.started":"2026-01-30T05:40:14.404281Z","shell.execute_reply":"2026-01-30T05:40:14.560706Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                         names       date_x  score  \\\n0                    Creed III  03/02/2023    73.0   \n1     Avatar: The Way of Water  12/15/2022    78.0   \n2  The Super Mario Bros. Movie  04/05/2023    76.0   \n3                      Mummies  01/05/2023    70.0   \n4                    Supercell  03/17/2023    61.0   \n\n                                           genre  \\\n0                                  Drama,¬†Action   \n1             Science Fiction,¬†Adventure,¬†Action   \n2  Animation,¬†Adventure,¬†Family,¬†Fantasy,¬†Comedy   \n3  Animation,¬†Comedy,¬†Family,¬†Adventure,¬†Fantasy   \n4                                         Action   \n\n                                            overview  \\\n0  After dominating the boxing world, Adonis Cree...   \n1  Set more than a decade after the events of the...   \n2  While working underground to fix a water main,...   \n3  Through a series of unfortunate events, three ...   \n4  Good-hearted teenager William always lived in ...   \n\n                                                crew  \\\n0  Michael B. Jordan, Adonis Creed, Tessa Thompso...   \n1  Sam Worthington, Jake Sully, Zoe Salda√±a, Neyt...   \n2  Chris Pratt, Mario (voice), Anya Taylor-Joy, P...   \n3  √ìscar Barber√°n, Thut (voice), Ana Esther Albor...   \n4  Skeet Ulrich, Roy Cameron, Anne Heche, Dr Quin...   \n\n                    orig_title     status            orig_lang     budget_x  \\\n0                    Creed III   Released              English   75000000.0   \n1     Avatar: The Way of Water   Released              English  460000000.0   \n2  The Super Mario Bros. Movie   Released              English  100000000.0   \n3                       Momias   Released   Spanish, Castilian   12300000.0   \n4                    Supercell   Released              English   77000000.0   \n\n        revenue country  \n0  2.716167e+08      AU  \n1  2.316795e+09      AU  \n2  7.244590e+08      AU  \n3  3.420000e+07      AU  \n4  3.409420e+08      US  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>names</th>\n      <th>date_x</th>\n      <th>score</th>\n      <th>genre</th>\n      <th>overview</th>\n      <th>crew</th>\n      <th>orig_title</th>\n      <th>status</th>\n      <th>orig_lang</th>\n      <th>budget_x</th>\n      <th>revenue</th>\n      <th>country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Creed III</td>\n      <td>03/02/2023</td>\n      <td>73.0</td>\n      <td>Drama,¬†Action</td>\n      <td>After dominating the boxing world, Adonis Cree...</td>\n      <td>Michael B. Jordan, Adonis Creed, Tessa Thompso...</td>\n      <td>Creed III</td>\n      <td>Released</td>\n      <td>English</td>\n      <td>75000000.0</td>\n      <td>2.716167e+08</td>\n      <td>AU</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Avatar: The Way of Water</td>\n      <td>12/15/2022</td>\n      <td>78.0</td>\n      <td>Science Fiction,¬†Adventure,¬†Action</td>\n      <td>Set more than a decade after the events of the...</td>\n      <td>Sam Worthington, Jake Sully, Zoe Salda√±a, Neyt...</td>\n      <td>Avatar: The Way of Water</td>\n      <td>Released</td>\n      <td>English</td>\n      <td>460000000.0</td>\n      <td>2.316795e+09</td>\n      <td>AU</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Super Mario Bros. Movie</td>\n      <td>04/05/2023</td>\n      <td>76.0</td>\n      <td>Animation,¬†Adventure,¬†Family,¬†Fantasy,¬†Comedy</td>\n      <td>While working underground to fix a water main,...</td>\n      <td>Chris Pratt, Mario (voice), Anya Taylor-Joy, P...</td>\n      <td>The Super Mario Bros. Movie</td>\n      <td>Released</td>\n      <td>English</td>\n      <td>100000000.0</td>\n      <td>7.244590e+08</td>\n      <td>AU</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Mummies</td>\n      <td>01/05/2023</td>\n      <td>70.0</td>\n      <td>Animation,¬†Comedy,¬†Family,¬†Adventure,¬†Fantasy</td>\n      <td>Through a series of unfortunate events, three ...</td>\n      <td>√ìscar Barber√°n, Thut (voice), Ana Esther Albor...</td>\n      <td>Momias</td>\n      <td>Released</td>\n      <td>Spanish, Castilian</td>\n      <td>12300000.0</td>\n      <td>3.420000e+07</td>\n      <td>AU</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Supercell</td>\n      <td>03/17/2023</td>\n      <td>61.0</td>\n      <td>Action</td>\n      <td>Good-hearted teenager William always lived in ...</td>\n      <td>Skeet Ulrich, Roy Cameron, Anne Heche, Dr Quin...</td>\n      <td>Supercell</td>\n      <td>Released</td>\n      <td>English</td>\n      <td>77000000.0</td>\n      <td>3.409420e+08</td>\n      <td>US</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"#converting datasets into HuggingFace datasets \nfrom datasets import Dataset\n\n# convert list to dataset first if not already\nfull_dataset = Dataset.from_list(data)\n\n# shuffle + take subset\ndataset = full_dataset.shuffle(seed=42).select(range(6000))\n\nlen(dataset)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tokenize(example):\n    tokens = tokenizer(\n        example[\"text\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=256\n    )\n    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n    return tokens\n\ndataset = dataset.map(tokenize, batched=False)\ndataset = dataset.remove_columns([\"text\"])\ndataset.set_format(\"torch\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Training args \ntraining_args = TrainingArguments(\n    output_dir=\"./movie-llm\",\n    per_device_train_batch_size=2,\n    gradient_accumulation_steps=4,\n    learning_rate=2e-4,\n    num_train_epochs=3,\n    fp16=True,\n\n    logging_strategy=\"steps\",   # üëà force logging\n    logging_steps=1,            # üëà every step\n    logging_first_step=True,\n\n    disable_tqdm=True,          # üëà KILLS progress bar (important)\n    report_to=\"none\",           # üëà no wandb / tensorboard\n    save_strategy=\"no\",\n    log_level=\"info\"\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Fine tuning the model \ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset\n)\nprint(\"üöÄ TRAINING STARTED\")\ntrainer.train()\nprint(\"‚úÖ TRAINING FINISHED\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#saving the finetuned model \ntrainer.model.save_pretrained(\"movie-lora-adapter\")\ntokenizer.save_pretrained(\"movie-lora-adapter\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"After saving the finetuned model we are loading that model as LORA_PATH and testing it.","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/input/d/jeevaaaa/movie-lora/movie-lora-adapter\nLORA_PATH = \"/kaggle/input/d/jeevaaaa/movie-lora/movie-lora-adapter\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T05:36:40.014297Z","iopub.execute_input":"2026-01-30T05:36:40.015186Z","iopub.status.idle":"2026-01-30T05:36:40.161778Z","shell.execute_reply.started":"2026-01-30T05:36:40.015147Z","shell.execute_reply":"2026-01-30T05:36:40.161049Z"}},"outputs":[{"name":"stdout","text":"adapter_config.json\t   README.md\t\t    tokenizer.json\nadapter_model.safetensors  special_tokens_map.json  tokenizer.model\nchat_template.jinja\t   tokenizer_config.json\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!unzip /kaggle/input/movie-lora-adapter/movie-lora-adapter.zip\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T05:34:57.638407Z","iopub.execute_input":"2026-01-30T05:34:57.639148Z","iopub.status.idle":"2026-01-30T05:34:57.781248Z","shell.execute_reply.started":"2026-01-30T05:34:57.639112Z","shell.execute_reply":"2026-01-30T05:34:57.780578Z"}},"outputs":[{"name":"stdout","text":"unzip:  cannot find or open /kaggle/input/movie-lora/movie-lora-adapter.zip, /kaggle/input/movie-lora/movie-lora-adapter.zip.zip or /kaggle/input/movie-lora/movie-lora-adapter.zip.ZIP.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!ls movie-lora-adapter\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T05:33:47.140001Z","iopub.execute_input":"2026-01-30T05:33:47.140350Z","iopub.status.idle":"2026-01-30T05:33:47.282074Z","shell.execute_reply.started":"2026-01-30T05:33:47.140314Z","shell.execute_reply":"2026-01-30T05:33:47.281025Z"}},"outputs":[{"name":"stdout","text":"ls: cannot access 'movie-lora-adapter': No such file or directory\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#using the finetuned model \nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom peft import PeftModel\n\nmodel = PeftModel.from_pretrained(\n    model,\n    LORA_PATH\n)\n\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T05:37:49.844435Z","iopub.execute_input":"2026-01-30T05:37:49.845287Z","iopub.status.idle":"2026-01-30T05:37:50.033689Z","shell.execute_reply.started":"2026-01-30T05:37:49.845248Z","shell.execute_reply":"2026-01-30T05:37:50.032963Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): PeftModelForCausalLM(\n      (base_model): LoraModel(\n        (model): LlamaForCausalLM(\n          (model): LlamaModel(\n            (embed_tokens): Embedding(32000, 2048)\n            (layers): ModuleList(\n              (0-21): 22 x LlamaDecoderLayer(\n                (self_attn): LlamaAttention(\n                  (q_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=2048, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=2048, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (k_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n                  (v_proj): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=2048, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=256, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n                )\n                (mlp): LlamaMLP(\n                  (gate_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n                  (up_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n                  (down_proj): Linear4bit(in_features=5632, out_features=2048, bias=False)\n                  (act_fn): SiLUActivation()\n                )\n                (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n                (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n              )\n            )\n            (norm): LlamaRMSNorm((2048,), eps=1e-05)\n            (rotary_emb): LlamaRotaryEmbedding()\n          )\n          (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n        )\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"#testing the finetuned model \nprompt = \"\"\"### Question: Recommend a science fiction movie with a twist.\n### Answer:\"\"\"\n\ninputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n\nwith torch.no_grad():\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=120,\n        do_sample=True,          # üëà IMPORTANT\n        temperature=0.4,         # low = controlled\n        top_p=0.9,\n        repetition_penalty=1.1,\n        eos_token_id=tokenizer.eos_token_id,\n    )\n\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T05:40:34.969791Z","iopub.execute_input":"2026-01-30T05:40:34.970558Z","iopub.status.idle":"2026-01-30T05:40:41.167402Z","shell.execute_reply.started":"2026-01-30T05:40:34.970529Z","shell.execute_reply":"2026-01-30T05:40:41.166760Z"}},"outputs":[{"name":"stdout","text":"### Question: Recommend a science fiction movie with a twist.\n### Answer: \"The Martian\" (2015) - A film about an astronaut stranded on Mars who must use his ingenuity and resourcefulness to survive. The twist is that the astronaut's wife was killed in a tragic accident before he left Earth, and he had to make his way back to Earth alone. This movie is a great example of how a twist can add depth and complexity to a story.\n","output_type":"stream"}],"execution_count":17}]}